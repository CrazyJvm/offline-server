include "common.conf"

app {
  database {
    dataSourceClass = "org.postgresql.ds.PGSimpleDataSource"
    properties {
      url: "jdbc:postgresql://localhost:7531/rules"
      user: ${database.user}
      password: ${database.password}
    }
    numThreads = 2
  }

  kafka {
    bootstrap.servers: "cnkafka8:9092,cnkafka9:9092,cnkafka10:9092"
    group.id: "jobsubmitter"
    fetch.maxRetries: "10"
    fetch.maxBytes: "10000"
  }

  submitter {
    interval: 120

    jobs: [

      // 数据导出一大波
      {
        name: "export_visit"
        jobInfo { job: "io.growing.offline.api.TestSparkJobV2", jobType: "class", properties { type: "visit", "spark.scheduler.pool": "backward", schema: "hdfs" } }
        submitInfo { interval: 3600, topicAndGroups:
          [
//            { group: "web-pv", topic: "vds-api-web-pv" },
//            { group: "mobile-pv", topic: "vds-api-mobile-pv" }
          ]
        }
      }

    ]
  }

  jobServer {
    sparkConfigs {
      spark.master: "local[2]"
      spark.app.name: "local-JobServer"
      // 配置到sparkContext.hadoopConfiguration
      hadoopConf {
        fs.ufile.impl: "org.apache.hadoop.fs.UFileFileSystem"
        fs.AbstractFileSystem.ufile.impl: "fs.AbstractFileSystem.ufile.impl"
        ufile.properties.file: "conf/ufile.properties"
      }
    }

    jobContext {
      // 此处定义所有JobContext内传递的配置参数,例如配置数据库连接
      database {
        // 数据导出需要的配置AI表
        project_settings {
          driver: "org.postgresql.Driver"
          //    url: "jdbc:postgresql://easydata.cp9cbbjb0tpe.rds.cn-north-1.amazonaws.com.cn:7531/growing"
          url: "jdbc:postgresql://localhost:7531/growing"
          user: ${database.user}
          password: ${database.password}
        }
      }

    }
  }

}

akka {
  actor {
    deployment {
      "/scheduler/jobServer/jobRouter" {
        dispatcher: "jobDispatcher"
        router: "round-robin-pool"
        nr-of-instances: 5
      }
      "/scheduler/jobServer/jobRouter/*" {
        mailbox: "jobPriorityQueue"
      }
    }
  }
}

jobDispatcher {
  type: "Dispatcher"
  executor: "fork-join-executor"
  fork-join-executor {
    parallelism-min: 4
    parallelism-factor: 2.0
    parallelism-max: 10
    task-peeking-mode: FIFO     // 设置FIFO模式
  }
  throughput: 10
}

jobPriorityQueue {
  mailbox-type: "io.growing.offline.models.JobPriorityQueue"
}