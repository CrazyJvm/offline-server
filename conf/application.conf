include "common.conf"

app {
  database {
    dataSourceClass = "org.postgresql.ds.PGSimpleDataSource"
    properties {
      url: ${database.rules_url}
      user: ${database.user}
      password: ${database.password}
    }
    numThreads = 2
  }

  kafka {
    bootstrap.servers: "cnkafka8:9092,cnkafka9:9092,cnkafka10:9092"
    group.id: "jobsubmitter"
    fetch.maxRetries: "10"
    fetch.maxBytes: "10000"
  }

  timeZone: "Asia/Shanghai"

  jobs: [

  ]


  submitter {
    interval: 120
  }

  scheduler {
    // failed job 重试的次数, debug的时候不重试
    maxRetries: 0
  }

  jobServer {
    sparkConfigs {
      // spark只接收spark.开头的配置信息
      spark {
        app.name: "JobServer"
        //        master: "local[*]"
        scheduler.listenerbus.eventqueue.size: 800000

        // itemProcessJob，es.nodes -> spark.es.nodes
        es {
          nodes: "internal-elb-cn-es-in-em-1318002520.cn-north-1.elb.amazonaws.com.cn"
          port: 9200
          index.auto.create: "true"
          mapping.id: "_id"
          batch.size.entries: 20000
          batch.size.bytes: 16mb
          circle.index.prefix: "circle-"
        }
      }


      // 配置到sparkContext.hadoopConfiguration
      hadoopConf {
        fs.ufile.impl: "org.apache.hadoop.fs.UFileFileSystem"
        fs.AbstractFileSystem.ufile.impl: "fs.AbstractFileSystem.ufile.impl"
        ufile.properties.file: "conf/ufile.properties"
      }
    }

    jobContext {
      // 此处定义所有JobContext内传递的配置参数,例如配置数据库连接
      database {
        // 数据导出需要的配置AI表
        project_settings {
          driver: "org.postgresql.Driver"
          url: ${database.project_settings_url}
          user: ${database.user}
          password: ${database.password}
        }

        //        ips_filter {
        //          driver: "org.postgresql.Driver"
        //          url: ${database.project_settings_url}
        //          user: ${database.user}
        //          password: ${database.password}
        //        }
      }

      // 在job的description中只显示下面定义的keys，默认包括startPos与stopPos
      descriptionKeys: "typ"

      invalidCS1: ${global.invalidCS1}

      zkUrl: "qaapp2"
      phoenix.tables: "user_mapping_sem, user, company, utm, devices, cs1_id_mapping, new_user, new_cs1"
      //      jdbc.tables: "ips_filter"
      outputPathPrefix: "hdfs:///user/apps/tmp/hfiles"
    }
  }

}

akka {
  actor {
    deployment {
      "/scheduler/jobServer/jobRouter" {
        dispatcher: "jobDispatcher"
        router: "round-robin-pool"
        nr-of-instances: 5
      }
      "/scheduler/jobServer/jobRouter/*" {
        mailbox: "jobPriorityQueue"
      }
    }
  }

  // wechat 发送消息
  http.host-connection-pool.client.proxy {
    http {
      host: "cngtwy"
      port: "3128"
    }
  }
}

jobDispatcher {
  type: "Dispatcher"
  executor: "fork-join-executor"
  fork-join-executor {
    parallelism-min: 4
    parallelism-factor: 2.0
    parallelism-max: 10
    task-peeking-mode: FIFO     // 设置FIFO模式
  }
  throughput: 10
}

jobPriorityQueue {
  mailbox-type: "io.growing.offline.models.JobPriorityQueue"
}

global {
  invalidCS1: "'undefined:undefined', 'user_id:', 'user_id:0', 'userId:访客', 'buid:', 'net:wifi', ' ', 'user_id:anonymous', 'net:3G', 'net:4G', 'uid:-1', 'id:0', 'datatype:Unkown', 'user_id:-1', 'net:unknown', 'user_id:N/A', 'net:2G', 'cloudstudy_ios:app_code', 'user_id:1'"
}
